{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bd3fb-5582-4747-8516-e22371fbc326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3812df-5b13-42e2-a32c-f28202514e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow.sklearn\n",
    "from itertools import product\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9efa36-a24a-4649-ba38-092f5ab1554e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 10:47:46 INFO mlflow.tracking.fluent: Experiment with name 'taller_grupo5' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow configurado correctamente\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Configuración de MLflow ----------------\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.195:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.195:5000\")  # Verificar que esté en ejecución\n",
    "mlflow.set_experiment(\"taller_grupo5\")\n",
    "\n",
    "# Configurar el autologging\n",
    "mlflow.sklearn.autolog(log_model_signatures=True, log_input_examples=True, registered_model_name=\"RandomForestModel\")\n",
    "print(\"MLflow configurado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7c6d46-9ae3-4cbb-a5e6-233ab1d6012c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Tabla 'penguins' creada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Conexión a MySQL ----------------\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"10.43.101.195\",  # ✅ Asegurar que es solo la IP\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admingrupo5\",\n",
    "    \"database\": \"data_db\",\n",
    "    \"port\": 3308  # ✅ Verificar el puerto correcto\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Eliminar la tabla si ya existe\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS penguins;\")\n",
    "\n",
    "    # Crear la tabla\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE penguins (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            species VARCHAR(50) NOT NULL,\n",
    "            island VARCHAR(50) NOT NULL,\n",
    "            culmen_length_mm FLOAT NOT NULL,\n",
    "            culmen_depth_mm FLOAT NOT NULL,\n",
    "            flipper_length_mm FLOAT NOT NULL,\n",
    "            body_mass_g FLOAT NOT NULL,\n",
    "            sex VARCHAR(10) NOT NULL\n",
    "        );\n",
    "    ''')\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Tabla 'penguins' creada exitosamente.\")\n",
    "\n",
    "    # Cerrar conexiones\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error al conectar a MySQL: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbd4e91-c764-4b6f-8a56-97e652fcac33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente. Registros insertados: 334\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Cargar el dataset desde CSV\n",
    "    df = pd.read_csv(\"/work/data/penguins_size.csv\").dropna()\n",
    "\n",
    "    # Conexión a MySQL\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Consulta SQL optimizada para inserción masiva\n",
    "    query = \"\"\"\n",
    "        INSERT INTO penguins (species, island, culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, sex)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir el dataframe a una lista de tuplas para ejecutar con `executemany`\n",
    "    data_tuples = list(df.itertuples(index=False, name=None))\n",
    "    \n",
    "    # Insertar los datos en una sola llamada para mejorar rendimiento\n",
    "    cursor.executemany(query, data_tuples)\n",
    "\n",
    "    # Confirmar cambios\n",
    "    conn.commit()\n",
    "    print(f\"Datos cargados exitosamente. Registros insertados: {cursor.rowcount}\")\n",
    "\n",
    "    # Cerrar conexiones\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error al conectar a MySQL: {err}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo CSV no fue encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e03edb6-d23f-43ba-aaaf-ea9a905eec3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Datos preprocesados exitosamente. Registros insertados: 1002\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Preprocesamiento de datos en MySQL ----------------\n",
    "try:\n",
    "    # Conectar a MySQL\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Extraer los datos de la tabla original\n",
    "    cursor.execute(\"SELECT id, species, island, culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, sex FROM penguins\")\n",
    "    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "    # Preprocesamiento: eliminar valores nulos\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Eliminar la tabla si ya existe\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS penguins_clean\")\n",
    "\n",
    "    # Crear la tabla limpia\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE penguins_clean (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            species VARCHAR(50),\n",
    "            island VARCHAR(50),\n",
    "            culmen_length_mm FLOAT,\n",
    "            culmen_depth_mm FLOAT,\n",
    "            flipper_length_mm FLOAT,\n",
    "            body_mass_g FLOAT,\n",
    "            sex VARCHAR(10)\n",
    "        );\n",
    "    ''')\n",
    "\n",
    "    # **Verificar qué columnas estamos insertando**\n",
    "    df = df[['species', 'island', 'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex']]\n",
    "\n",
    "    # **Convertir a tuplas**\n",
    "    data = [tuple(row) for row in df.to_numpy()]\n",
    "\n",
    "    # **Insertar los datos limpios con `executemany()`**\n",
    "    query = \"\"\"\n",
    "        INSERT INTO penguins_clean (species, island, culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, sex)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    cursor.executemany(query, data)\n",
    "\n",
    "    # Confirmar cambios\n",
    "    conn.commit()\n",
    "    print(f\"Datos preprocesados exitosamente. Registros insertados: {cursor.rowcount}\")\n",
    "\n",
    "    # Cerrar conexiones\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error al conectar a MySQL: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2eb002f-3d97-4404-874b-29ab1656203c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente desde MySQL\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=4, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=4, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=4, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=4, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=4, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=6, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=6, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=50; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=6, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=6, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=6, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=8, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=8, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .......max_depth=8, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=8, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=8, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END .....max_depth=10, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=25; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END ......max_depth=10, max_features=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END .....max_depth=10, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END .....max_depth=10, max_features=4, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'RandomForestModel' already exists. Creating a new version of this model...\n",
      "2025/03/16 11:54:34 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: RandomForestModel, version 42\n",
      "Created version '42' of model 'RandomForestModel'.\n",
      "2025/03/16 11:54:37 INFO mlflow.sklearn.utils: Logging the 5 best runs, 43 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo encontrado con parámetros: {'max_depth': 6, 'max_features': 2, 'n_estimators': 25}\n",
      "Todos los experimentos fueron registrados en MLflow.\n"
     ]
    }
   ],
   "source": [
    "#GridSearch\n",
    "\n",
    "# ---------------- Conectar y obtener datos de MySQL ----------------\n",
    "try:\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Obtener datos preprocesados\n",
    "    cursor.execute(\"SELECT species, culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g FROM penguins_clean\")\n",
    "    df = pd.DataFrame(cursor.fetchall(), columns=[desc[0] for desc in cursor.description])\n",
    "\n",
    "    # Cerrar conexión a MySQL\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Datos cargados exitosamente desde MySQL\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error al conectar a MySQL: {err}\")\n",
    "    exit()\n",
    "\n",
    "# ---------------- Preparación de datos ----------------\n",
    "X = df[['culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y = df['species']\n",
    "\n",
    "# Convertir la variable objetivo a valores numéricos con LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Guardar el LabelEncoder para usarlo en la inferencia\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---------------- Configuración de MLflow ----------------\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.195:5000\")\n",
    "mlflow.set_experiment(\"taller_grupo5\")\n",
    "\n",
    "# ---------------- Definir GridSearch con hiperparámetros ----------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [25, 50, 75, 100],\n",
    "    \"max_depth\": [4, 6, 8, 10],\n",
    "    \"max_features\": [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Crear modelo base\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Aplicar GridSearchCV para encontrar la mejor combinación\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=2)\n",
    "\n",
    "# Guardar el LabelEncoder para usarlo en la inferencia\n",
    "label_encoder_path = \"label_encoder.pkl\"\n",
    "with open(label_encoder_path, \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "    \n",
    "# ---------------- Ejecutar entrenamiento con MLflow ----------------\n",
    "with mlflow.start_run(run_name=\"rf_grid_search_v5\"):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener mejor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Registrar hiperparámetros en MLflow\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Guardar el mejor modelo en MLflow\n",
    "    mlflow.sklearn.log_model(best_model, \"RandomForestModel\")\n",
    "\n",
    "    # Subir el LabelEncoder a MLflow\n",
    "    mlflow.log_artifact(label_encoder_path)\n",
    "\n",
    "    print(f\"Mejor modelo encontrado con parámetros: {grid_search.best_params_}\")\n",
    "\n",
    "print(\"Todos los experimentos fueron registrados en MLflow.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
